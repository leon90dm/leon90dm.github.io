---
layout:     post
title:      "å¦‚ä½•é€‰æ‹©åˆé€‚çš„å…ˆéªŒåˆ†å¸ƒ"
subtitle:   ""
date:       2020-01-13
author:     "BilboDai"
catalog: true
tags:
    - probability
---

### ä¸¤ç±» priors

1. ä¸»è§‚priors :  å…ˆéªŒæ—¶å¤šåŠ å…¥å‚ä¸è€…çš„è§‚ç‚¹
2. å®¢è§‚priorsï¼šè®©æ•°æ®æ›´å¤šå‚ä¸å½±å“åéªŒåˆ†å¸ƒ



### æœ‰ç”¨çš„å…ˆéªŒåˆ†å¸ƒ

1. Gammaåˆ†å¸ƒ

   
   $$
   f(x | \alpha, \beta)=\frac{\beta^{\alpha} x^{\alpha-1} e^{-\beta x}}{\Gamma(\alpha)}
   $$
   

2. The Wishart distribution

   æŠŠéšæœºå˜é‡ä»å•ä¸ªå€¼æ‹“å±•åˆ°å¤šç»´

   ![wischard](https://tva1.sinaimg.cn/large/006tNbRwly1gawfvzjo4fj30ks098749.jpg)

3. Beta åˆ†å¸ƒ

   
   $$
   f_{X}(x | \alpha, \beta)=\frac{x^{(\alpha-1)}(1-x)^{(\beta-1)}}{B(\alpha, \beta)}
   $$
   

   å¦‚æœæˆ‘ä»¬ä»å…ˆéªŒåˆ†å¸ƒ $$Beta(1,1)$$ å®é™…æ˜¯ä¸€ä¸ªå‡åŒ€åˆ†å¸ƒå¼€å§‹ï¼Œå½“è§‚å¯Ÿåˆ° $$X \sim Binomial(N,p)$$ æ ·æœ¬åçš„åéªŒåˆ†å¸ƒä¸ºï¼š$$Beta(1+X, 1+N-X)$$ 

   è¿™é‡Œï¼Œ $$Beta$$ ä¹Ÿè¢«ç§°ä½œ $$Binomial$$ çš„å…±è½­å…ˆéªŒï¼Œå½¢ä¼¼æ»¡è¶³å¦‚ä¸‹ç­‰å¼çš„ $$p_{\beta}$$ï¼š

   
   $$
   \underbrace{p_{\beta}}_{\text { prior }} \cdot \overbrace{f_{\alpha}(X)}^{\text {data }}=\overbrace{p_{\beta^{\prime}}}^{\text {posterior }}
   $$
   

   æ¢ $$p_{\beta} = Beta,\ f_{\alpha} = Binomial$$ å¾—ï¼š

    

$$
\underbrace{\text { Beta }}_{\text { prior }} \cdot \overbrace{\text { Binomial }}^{\text {data }}=\overbrace{\text { Beta }}^{\text {posterior }}
$$

â€‹	

â€‹		ğŸ‘‰ å…±è½­å…ˆéªŒçš„å¥½å¤„æ˜¯ï¼š**å¯ä»¥é¿å…ä½¿ç”¨MCMCè¿›è¡Œè¿‘ä¼¼æ¨æ–­ï¼Œè€Œç›´æ¥è¿›å…¥åéªŒã€‚**

### Bayesian Multi-Armed Bandits

multi-armed bandits çš„ç›®æ ‡å°±æ˜¯è¦æ‰¾å‡ºé‚£ä¸ªèƒ½äº§ç”Ÿæœ€å¤§æ”¶ç›Šæ¦‚ç‡çš„ armã€‚ç®—æ³•æµç¨‹å¦‚ä¸‹ï¼š

1. Sample a random variable $$X_b$$ from the prior of bandit $$b$$, for all $$b$$.
2. Select the bandit with largest sample, i.e. select $$B = argmax\ X_b$$.
3. Observe the result of pulling bandit $$B$$ , and update your prior on bandit $$B$$.
4. return to step 1.

ğŸ‘‰ æ‹“å±•

1ï¼‰ åœ¨æ›´æ–°priorçš„æ—¶å€™ï¼Œå¯åŠ ä¸Šä¸€ä¸ª `rate` 

```python
self.wins[choice] = rate*self.wins[choice] + result
self.trials[choice] = rate*self.trials[choice] + 1
```

### The Resulting ranking algorithm

The Resulting Ranking algorithm is quite straightforward,  each new time the comments page is loaded, the score for each comment is sampled from a Beta(1+U,1+D), comments are then ranked by this score in descending order.

> This randomization has a unique benefit in that even untouched comments (U=1,D=0) have some chance of being seen even in threads with 5000+ comments (something that is not happening now), but, at the same time, the user is not likely to be inundated with rating these new comments.

### Stock Returns

å‡è®¾ $$S_t$$ æ˜¯å·²çŸ¥è‚¡ç¥¨åœ¨ç¬¬ $$t$$ å¤©çš„ä»·æ ¼ï¼Œé‚£ä¹ˆç¬¬ $$t$$ å¤©çš„æ”¶ç›Šç‡ä¸ºï¼š


$$
r_t = \frac{S_t - S_{t-1}}{S_{t-1}}
$$


é‚£ä¹ˆè¿™åªè‚¡ç¥¨çš„å¤©æ”¶ç›Šç‡æœŸæœ›ä¸ºï¼š $$\mu = E[r_t]$$.















